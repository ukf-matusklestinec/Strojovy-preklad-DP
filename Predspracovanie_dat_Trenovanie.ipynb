{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ukf-matusklestinec/Strojovy-preklad-DP/blob/main/Predspracovanie_dat_Trenovanie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Jqtow9eJb-O"
      },
      "outputs": [],
      "source": [
        "# KORPUSY\n",
        "# https://opus.nlpl.eu/Europarl/en&sk/v7/Europarl\n",
        "\n",
        "\n",
        "\n",
        "# https://github.com/google/sentencepiece - SentencePiece\n",
        "# https://opennmt.net/OpenNMT-tf/configuration.html - dokumentácia pre config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fLWVqsZQs9R",
        "outputId": "131c27a1-ff23-470f-b261-9903ab824703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting OpenNMT-py\n",
            "  Downloading OpenNMT_py-3.5.0-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.8/262.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<2.3,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.1.0+cu121)\n",
            "Collecting configargparse (from OpenNMT-py)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Collecting ctranslate2<5,>=3.24 (from OpenNMT-py)\n",
            "  Downloading ctranslate2-4.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.15.2)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.2.5)\n",
            "Collecting waitress (from OpenNMT-py)\n",
            "  Downloading waitress-3.0.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyonmttok<2,>=1.35 (from OpenNMT-py)\n",
            "  Downloading pyonmttok-1.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (6.0.1)\n",
            "Collecting sacrebleu (from OpenNMT-py)\n",
            "  Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz (from OpenNMT-py)\n",
            "  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from OpenNMT-py)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasttext-wheel (from OpenNMT-py)\n",
            "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (3.7.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=3.24->OpenNMT-py) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=3.24->OpenNMT-py) (1.25.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.60.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.5.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (2.1.0)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel->OpenNMT-py)\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (8.1.7)\n",
            "Collecting portalocker (from sacrebleu->OpenNMT-py)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->OpenNMT-py)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (4.9.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (4.66.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.6.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.3->OpenNMT-py) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.3,>=2.0.1->OpenNMT-py) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py) (2.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->OpenNMT-py) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->OpenNMT-py) (0.1.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy->OpenNMT-py) (0.16.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.3,>=2.0.1->OpenNMT-py) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.3->OpenNMT-py) (3.2.2)\n",
            "Installing collected packages: waitress, rapidfuzz, pyonmttok, pybind11, pyahocorasick, portalocker, ctranslate2, configargparse, colorama, sacrebleu, fasttext-wheel, OpenNMT-py\n",
            "Successfully installed OpenNMT-py-3.5.0 colorama-0.4.6 configargparse-1.7 ctranslate2-4.0.0 fasttext-wheel-0.9.2 portalocker-2.8.2 pyahocorasick-2.0.0 pybind11-2.11.1 pyonmttok-1.37.1 rapidfuzz-3.6.1 sacrebleu-2.4.0 waitress-3.0.0\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=d751170cbea012cdcfa2de680b7a432221c68586f16e91394bb4da70a3436508\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece\n",
        "!pip3 install OpenNMT-py\n",
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HMvnB4x9L4ji"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import sentencepiece as spm\n",
        "import time\n",
        "from langdetect import detect, LangDetectException  # pre identifikáciu jazykov\n",
        "import unicodedata  # pre normalizáciu unicode\n",
        "import torch\n",
        "import sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Kvc1X3N6Qy-I"
      },
      "outputs": [],
      "source": [
        "en_parl = \"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.en\"\n",
        "sk_parl = \"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.sk\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua4lYSqcRE0A"
      },
      "source": [
        "## Filtrovanie/Čistenie korpusu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxhHTU8SRJA4",
        "outputId": "127a3cf5-7b2a-4b7d-a17d-06905d75463c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rozmery datasetu (riadky, stĺpce): (640715, 2)\n",
            "Normalizácia na základe UNICODE znakov\t\t\t         Riadky: 640715 | Odstránené riadky: 0, Čas: 6.29 sekúnd\n",
            "Riadky bez NaN hodnôt\t\t\t\t\t         Riadky: 640715 | Odstránené riadky: 0, Čas: 6.74 sekúnd\n",
            "Odstránenie riadkov, kde sa riadok source rovná riadku target\t Riadky: 637465 | Odstránené riadky: 3250, Čas: 7.00 sekúnd\n",
            "Odstránenie duplicitných/rovnakých riadkov\t\t\t Riadky: 621617 | Odstránené riadky: 15848, Čas: 8.33 sekúnd\n",
            "Odstránenie príliš dlhých viet source/target\t\t         Riadky: 621601 | Odstránené riadky: 16, Čas: 11.44 sekúnd\n",
            "Konverzia špeciálnych znakov\t\t\t        \t Riadky: 621601 | Odstránené riadky: 16, Čas: 16.41 sekúnd\n",
            "Odstránenie znakov, ktoré nie sú písmená/čísla\t\t\t Riadky: 621601 | Odstránené riadky: 0, Čas: 21.50 sekúnd\n",
            "Riadky sú konvertované na malé písmená (lowercase)\t\t Riadky: 621601 | Odstránené riadky: 0, Čas: 22.85 sekúnd\n",
            "Riadky bez NaN hodnôt\t\t\t\t\t         Riadky: 621597 | Odstránené riadky: 4, Čas: 26.51 sekúnd\n",
            "Kontrola jazykov\t\t\t\t\t\t         Riadky: 611479 | Odstránené riadky: 10118, Čas: 6309.47 sekúnd\n",
            "Prehodenie poradia riadkov\t\t\t\t\t\t Riadky: 611479\n",
            "Celkový prejdený čas: 6309.93 sekúnd\n",
            "Source súbor uložený: /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.en-filtered.en\n",
            "Target súbor uložený: /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.sk-filtered.sk\n"
          ]
        }
      ],
      "source": [
        "def print_status(operacia, pocet_riadkov, pocet_odst_riadkov, prejdeny_cas):\n",
        "    print(f\"{operacia} Riadky: {pocet_riadkov} | Odstránené riadky: {pocet_odst_riadkov}, Čas: {prejdeny_cas:.2f} sekúnd\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "df_source = pd.read_csv(en_parl, names=['Source'], sep=\"\\0\", quoting=csv.QUOTE_NONE, skip_blank_lines=False) # dataset pre anglický text (source)\n",
        "df_target = pd.read_csv(sk_parl, names=['Target'], sep=\"\\0\", quoting=csv.QUOTE_NONE, skip_blank_lines=False) # dataset pre slovenský text (target)\n",
        "df = pd.concat([df_source, df_target], axis=1)\n",
        "print(\"Rozmery datasetu (riadky, stĺpce):\", df.shape)\n",
        "\n",
        "# aby fungovala normalizácia\n",
        "df['Source'] = df['Source'].astype(str)\n",
        "df['Target'] = df['Target'].astype(str)\n",
        "\n",
        "# Unicode normalizácia\n",
        "df['Source'] = df['Source'].apply(lambda x: unicodedata.normalize('NFKC', x))\n",
        "df['Target'] = df['Target'].apply(lambda x: unicodedata.normalize('NFKC', x))\n",
        "print_status(\"Normalizácia na základe UNICODE znakov\\t\\t\\t        \", df.shape[0], 0, time.time() - start_time)\n",
        "\n",
        "\n",
        "# Odstránenie NaN hodnôt\n",
        "pocet_riadkov = df.shape[0]\n",
        "df = df.dropna()\n",
        "odstranene_riadky = pocet_riadkov - df.shape[0]\n",
        "print_status(\"Riadky bez NaN hodnôt\\t\\t\\t\\t\\t        \", df.shape[0], odstranene_riadky, time.time() - start_time)\n",
        "\n",
        "\n",
        "# Odstránenie riadkov kde sa riadok source rovná riadku target\n",
        "pocet_riadkov = df.shape[0]\n",
        "df = df[df['Source'] != df['Target']]\n",
        "odstranene_riadky = pocet_riadkov - df.shape[0]\n",
        "print_status(\"Odstránenie riadkov, kde sa riadok source rovná riadku target\\t\", df.shape[0], odstranene_riadky, time.time() - start_time)\n",
        "\n",
        "\n",
        "# Odstránenie duplikátov\n",
        "pocet_riadkov = df.shape[0]\n",
        "df = df.drop_duplicates()\n",
        "odstranene_riadky = pocet_riadkov - df.shape[0]\n",
        "print_status(\"Odstránenie duplicitných/rovnakých riadkov\\t\\t\\t\", df.shape[0], odstranene_riadky, time.time() - start_time)\n",
        "\n",
        "\n",
        "# Odstránenie v dôsledku príliš dlhých viet source/target\n",
        "# Dĺžka, ktorá sa považuje za \"príliš dlhú\" záleží od jazyka\n",
        "pocet_riadkov = df.shape[0]\n",
        "max_sentence_length = 175\n",
        "df = df[~((df['Source'].str.count(' ') > max_sentence_length) | (df['Target'].str.count(' ') > max_sentence_length))]\n",
        "odstranene_riadky = pocet_riadkov - df.shape[0]\n",
        "print_status(\"Odstránenie príliš dlhých viet source/target\\t\\t        \", df.shape[0], odstranene_riadky, time.time() - start_time)\n",
        "\n",
        "# Odstránenie stopwords\n",
        "#stop_words_en = STOP_WORDS_EN\n",
        "#stop_words_sk = STOP_WORDS_SK\n",
        "#df['Source'] = df['Source'].apply(lambda x: ' '.join([w for w in x.split() if w not in stop_words_en]))\n",
        "#df['Target'] = df['Target'].apply(lambda x: ' '.join([w for w in x.split() if w not in stop_words_sk]))\n",
        "#odstranene_riadky = 0\n",
        "#print_status(\"Odstránenie stopwords\\t\\t\\t\\t\\t        \", df.shape[0], odstranene_riadky, time.time() - start_time)\n",
        "\n",
        "# Stemming\n",
        "#stemmer = PorterStemmer()\n",
        "#df['Source'] = df['Source'].apply(lambda x: ' '.join([stemmer.stem(w) for w in x.split()]))\n",
        "#df['Target'] = df['Target'].apply(lambda x: ' '.join([stemmer.stem(w) for w in x.split()]))\n",
        "#print_status(\"Stemming\\t\\t\\t\\t\\t\\t\\t        \", df.shape[0], odstranene_riadky, time.time() - start_time)\n",
        "\n",
        "# konverzia špeciálnych znakov\n",
        "pocet_riadkov = df.shape[0]\n",
        "\n",
        "df['Source'] = df['Source'].str.replace(r'&amp;', '&', regex=True)\n",
        "df['Source'] = df['Source'].str.replace(r'&quot;', '\"', regex=True)\n",
        "df['Source'] = df['Source'].str.replace(r'&apos;', '\\'', regex=True)\n",
        "df['Source'] = df['Source'].str.replace(r'&lt;', '<', regex=True)\n",
        "df['Source'] = df['Source'].str.replace(r'&gt;', '>', regex=True)\n",
        "\n",
        "df['Target'] = df['Target'].str.replace(r'&amp;', '&', regex=True)\n",
        "df['Target'] = df['Target'].str.replace(r'&quot;', '\"', regex=True)\n",
        "df['Target'] = df['Target'].str.replace(r'&apos;', '\\'', regex=True)\n",
        "df['Target'] = df['Target'].str.replace(r'&lt;', '<', regex=True)\n",
        "df['Target'] = df['Target'].str.replace(r'&gt;', '>', regex=True)\n",
        "print_status(\"Konverzia špeciálnych znakov\\t\\t\\t        \t\", df.shape[0], odstranene_riadky, time.time() - start_time)\n",
        "\n",
        "# Odstránenie znakov, ktoré nie sú písmená/čísla\n",
        "df['Source'] = df['Source'].str.replace('[^\\w\\s]', '', regex=True)\n",
        "df['Target'] = df['Target'].str.replace('[^\\w\\s]', '', regex=True)\n",
        "odstranene_riadky = pocet_riadkov - df.shape[0]\n",
        "print_status(\"Odstránenie znakov, ktoré nie sú písmená/čísla\\t\\t\\t\", df.shape[0], odstranene_riadky, time.time() - start_time)\n",
        "\n",
        "\n",
        "# konverzia na malé písmená\n",
        "pocet_riadkov = df.shape[0]\n",
        "df['Source'] = df['Source'].str.lower()\n",
        "df['Target'] = df['Target'].str.lower()\n",
        "prejdeny_cas = time.time() - start_time\n",
        "odstranene_riadky = pocet_riadkov - df.shape[0] # tu je to len, aby to pasovalo pre funkciu print_status\n",
        "print_status(\"Riadky sú konvertované na malé písmená (lowercase)\\t\\t\", df.shape[0], odstranene_riadky, time.time() - start_time)\n",
        "\n",
        "\n",
        "# Nahradenie prázdnych riadkov NaN\n",
        "df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
        "\n",
        "# Dodatočné odstránenie riadkov, kde je NaN, ktoré mohli vzniknúť v dôsledku minulých krokov\n",
        "pocet_riadkov = df.shape[0]\n",
        "df = df.dropna()\n",
        "odstranene_riadky = pocet_riadkov - df.shape[0]\n",
        "print_status(\"Riadky bez NaN hodnôt\\t\\t\\t\\t\\t        \", df.shape[0], odstranene_riadky, time.time() - start_time)\n",
        "\n",
        "# kontrola jazyka - tento proces trvá najdlhšie\n",
        "def safe_detect(text):\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except LangDetectException:\n",
        "        return None\n",
        "\n",
        "pocet_riadkov = df.shape[0]\n",
        "df['source_jazyk'] = df['Source'].apply(lambda x: safe_detect(x) if x and len(x.split()) > 1 else None)\n",
        "df['target_jazyk'] = df['Target'].apply(lambda x: safe_detect(x) if x and len(x.split()) > 1 else None)\n",
        "\n",
        "df = df[(df['source_jazyk'] == \"en\") & (df['target_jazyk'] == \"sk\")]\n",
        "df.drop(columns=['source_jazyk', 'target_jazyk'], inplace=True)\n",
        "odstranene_riadky = pocet_riadkov - df.shape[0]\n",
        "print_status(\"Kontrola jazykov\\t\\t\\t\\t\\t\\t        \", df.shape[0], odstranene_riadky, time.time() - start_time)\n",
        "\n",
        "\n",
        "# Zmenenie poradia riadkov\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True) # pridanie random_state, aby sme dostali vždy rovnako zamiešaný dataset\n",
        "print(\"Prehodenie poradia riadkov\\t\\t\\t\\t\\t Riadky:\", df.shape[0])\n",
        "\n",
        "prejdeny_cas = time.time() - start_time\n",
        "print(f\"Celkový prejdený čas: {prejdeny_cas:.2f} sekúnd\")\n",
        "\n",
        "source_subor = en_parl+'-filtered.'+ \"en\"\n",
        "target_subor = sk_parl+'-filtered.'+ \"sk\"\n",
        "\n",
        "df_source_en = df[\"Source\"]\n",
        "df_target_sk = df[\"Target\"]\n",
        "\n",
        "df_source_en.to_csv(source_subor, header=False, index=False, quoting=csv.QUOTE_NONE, sep=\"\\n\")\n",
        "print(\"Source súbor uložený:\", source_subor)\n",
        "df_target_sk.to_csv(target_subor, header=False, index=False, quoting=csv.QUOTE_NONE, sep=\"\\n\")\n",
        "print(\"Target súbor uložený:\", target_subor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4PQ8Sr03KY9"
      },
      "source": [
        "## Subwording"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O15cQXs34F58"
      },
      "outputs": [],
      "source": [
        "en_filt = r\"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.en-filtered.en\"\n",
        "sk_filt = r\"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.sk-filtered.sk\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_Lvxmw13O6G",
        "outputId": "3a103efd-a03d-49a0-92d8-ed984ed5b07b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trénovanie SentencePiece modelu bolo pre source súbor dokončené\n",
            "Trénovanie SentencePiece modelu bolo pre target súbor dokončené\n"
          ]
        }
      ],
      "source": [
        "#https://github.com/google/sentencepiece\n",
        "\n",
        "\n",
        "#Parametre\n",
        "vocab_size = 8000\n",
        "character_coverage = 0.9995\n",
        "\n",
        "# pre prípad veľkých korpusov -> --train_extremely_large_corpus=false\n",
        "\n",
        "# Model pre subwordovanie anglického textu (source)\n",
        "source = f'--input={en_filt} --model_prefix=source --vocab_size={vocab_size} --hard_vocab_limit=false --character_coverage={character_coverage} --split_digits=true --model_type=unigram'\n",
        "spm.SentencePieceTrainer.train(source)\n",
        "print(\"Trénovanie SentencePiece modelu bolo pre source súbor dokončené\")\n",
        "\n",
        "\n",
        "# Model pre subwordovanie slovenského textu (target)\n",
        "target = f'--input={sk_filt} --model_prefix=target --vocab_size={vocab_size} --hard_vocab_limit=false --character_coverage={character_coverage} --split_digits=true --model_type=unigram'\n",
        "spm.SentencePieceTrainer.train(target)\n",
        "print(\"Trénovanie SentencePiece modelu bolo pre target súbor dokončené\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XPIyMvNVGxTm"
      },
      "outputs": [],
      "source": [
        "source_model = r\"/content/source.model\"\n",
        "target_model = r\"/content/target.model\"\n",
        "source_subworded = \"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/source_subworded\"\n",
        "target_subworded = \"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/target_subworded\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyAlHd07Hc0v",
        "outputId": "2fd556e4-0ced-4c08-d137-2f0706a26939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spracovaných 100000 riadkov v /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.en-filtered.en\n",
            "Spracovaných 200000 riadkov v /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.en-filtered.en\n",
            "Spracovaných 300000 riadkov v /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.en-filtered.en\n",
            "Spracovaných 400000 riadkov v /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.en-filtered.en\n",
            "Spracovaných 500000 riadkov v /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.en-filtered.en\n",
            "Spracovaných 600000 riadkov v /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.en-filtered.en\n",
            "Subwordovanie Source súboru bolo dokončené: /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/source_subworded\n",
            "Spracovaných 100000 riadkov v /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.sk-filtered.sk\n",
            "Spracovaných 200000 riadkov v /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.sk-filtered.sk\n",
            "Spracovaných 300000 riadkov v /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.sk-filtered.sk\n",
            "Spracovaných 400000 riadkov v /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.sk-filtered.sk\n",
            "Spracovaných 500000 riadkov v /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.sk-filtered.sk\n",
            "Spracovaných 600000 riadkov v /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/europarl.sk-en.sk-filtered.sk\n",
            "Subwordovanie Target súboru bolo dokončené: /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/target_subworded\n"
          ]
        }
      ],
      "source": [
        "def subwordovanie(sp, vstup, vystup, interval=100000):\n",
        "    try:\n",
        "        with open(vstup, encoding=\"utf-8\") as vstup, open(vystup, \"w+\", encoding=\"utf-8\") as vystup:\n",
        "            for i, line in enumerate(vstup):\n",
        "                line = line.strip()\n",
        "                tokens = sp.encode_as_pieces(line)\n",
        "                vystup.write(\" \".join(tokens) + \"\\n\")\n",
        "\n",
        "                if (i + 1) % interval == 0:\n",
        "                    print(f\"Spracovaných {i + 1} riadkov v {vstup}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Nastala chyba v procese {vstup}: {e}\")\n",
        "\n",
        "sp = spm.SentencePieceProcessor()\n",
        "\n",
        "sp.load(source_model)\n",
        "subwordovanie(sp, en_filt, source_subworded)\n",
        "print(f\"Subwordovanie Source súboru bolo dokončené: {source_subworded}\")\n",
        "\n",
        "sp.load(target_model)\n",
        "subwordovanie(sp, sk_filt, target_subworded)\n",
        "print(f\"Subwordovanie Target súboru bolo dokončené: {target_subworded}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2unc3y_OBsW"
      },
      "source": [
        "## Výpis riadkov súboru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJE75HqLOJK3",
        "outputId": "c635c36c-c2bc-4265-ebe2-9ef280b19e89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁i ▁would ▁refer ▁in ▁particular ▁to ▁green ▁public ▁procurement s ▁which ▁will ▁allow ▁public ▁sector ▁agencies ▁to ▁play ▁a ▁leading ▁role ▁in ▁saving ▁energy ▁by ▁making ▁use ▁of ▁the ▁new ▁technological ▁applications ▁of ▁ict\n",
            "▁the ▁presence ▁of ▁origin ▁marking ▁would ▁surely ▁have ▁provided ▁a ▁guarantee ▁of ▁product ▁quality ▁and ▁protection\n",
            "▁the ▁open ▁scope ▁of ▁the ▁legislation ▁as ▁recommended ▁by ▁the ▁environment ▁committee ▁is ▁a ▁much ▁better ▁approach ▁than ▁that ▁proposed ▁by ▁the ▁commission\n",
            "▁of ▁course ▁this ▁means ▁that ▁if ▁one ▁million ▁european ▁citizens ▁wish ▁to ▁dispens e ▁with ▁the ▁strasbourg ▁site ▁that ▁desire ▁too ▁must ▁be ▁he ed ed\n",
            "▁indeed ▁the ▁eu ▁often ▁does ▁not ▁appear ▁to ▁know ▁who ▁it ▁is ▁actually ▁funding ▁and ▁who ▁is ▁pull ing ▁its ▁ str ing s\n",
            "▁women ▁are ▁the ▁favour it e ▁victims ▁of ▁the ▁recession ▁due ▁to ▁redundancies ▁primari ly ▁affect ing ▁precarious ▁jobs\n",
            "\n",
            "▁rád ▁by ▁som ▁spomenul ▁najmä ▁ekologické ▁verejné ▁obstarávanie ▁ktoré ▁agentúra m ▁verejné ho ▁sektora ▁umožní ▁zohrávať ▁vedúcu ▁úlohu ▁pri ▁úspor e ▁energií ▁prostredníctvom ▁používania ▁nových ▁technologický ch ▁aplikáci í ▁i kt\n",
            "▁označovanie ▁pôvodu ▁by ▁určite ▁poskytlo ▁záruk u ▁kvality ▁výrobkov ▁a ▁ochrany\n",
            "▁otvorený ▁rozsah ▁pôsobnosti ▁tohto ▁právne ho ▁predpis u ▁v ▁zmysle ▁odporúčania ▁výboru ▁pre ▁životné ▁prostredie ▁je ▁o veľa ▁lepší m ▁prístup om ▁ako ▁návrh ▁ktorý ▁predložila ▁komisia\n",
            "▁samozrejme ▁to ▁znamená ▁že ▁ak ▁sa ▁chce ▁jeden ▁milión ▁európskych ▁občanov ▁vzdať ▁s í dla ▁v ▁štrasburgu ▁musíme ▁tomu ▁venovať ▁pozornosť\n",
            "▁naozaj ▁často ▁sa ▁zdá ▁že ▁eú ▁nev ie ▁k o ho ▁v ▁skutočnosti ▁financuje ▁a ▁kto ▁ťa h á ▁za ▁jej ▁ nit ky\n",
            "▁ženy ▁sú ▁hlavným i ▁obeťami ▁recesie ▁v ▁dôsledku ▁pre púšťa nia ▁týkajúce ho ▁sa ▁hlavne ▁neist ých ▁pracovný ch ▁miest\n"
          ]
        }
      ],
      "source": [
        "with open(source_subworded, \"r\", encoding=\"utf-8\") as file:\n",
        "    for i, line in enumerate(file):\n",
        "        print(line.strip())\n",
        "        if i >= 5:\n",
        "            break\n",
        "\n",
        "print()\n",
        "\n",
        "with open(target_subworded, \"r\", encoding=\"utf-8\") as file:\n",
        "    for i, line in enumerate(file):\n",
        "        print(line.strip())\n",
        "        if i >= 5:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaZHsKCBONyA"
      },
      "source": [
        "##Rozdelenie dát na množiny"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3quZI0QiOR02"
      },
      "source": [
        "Dáta rozdelujeme do 3 častí:\n",
        "\n",
        "    trénovací dataset - používa sa na trénovanie modelu;\n",
        "    development dataset - používa sa na validáciu modelu počas trénovania, aby sa mohli vylepšiť parametre modelu\n",
        "    testovací dataset - používa sa na konečné vyhodotenie (evaluáciu) modelu na modelom nevidených dátach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nu2oO6BoPGp3"
      },
      "outputs": [],
      "source": [
        "source_subor = r\"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/source_subworded\"\n",
        "target_subor = r\"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/target_subworded\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9-kr-n2_OVdo"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "# Veľkosť súborov pre dev a test text\n",
        "data_size = 4000\n",
        "\n",
        "development = data_size\n",
        "test = data_size\n",
        "\n",
        "\n",
        "def train_test_dev(development, test, source_subor, target_subor):\n",
        "    df_source = pd.read_csv(source_subor, names=['Source'], sep=\"\\0\", quoting=csv.QUOTE_NONE, skip_blank_lines=False, encoding=\"utf-8\")\n",
        "    df_target = pd.read_csv(target_subor, names=['Target'], sep=\"\\0\", quoting=csv.QUOTE_NONE, skip_blank_lines=False, encoding=\"utf-8\")\n",
        "    df = pd.concat([df_source, df_target], axis=1)\n",
        "\n",
        "    # Odstránenie prázdnych riadkov\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # Zamiešanie datasetu\n",
        "    df = df.sample(frac=1, random_state=42).reset_index(drop=True) # pridanie random_state, aby sme dostali vždy rovnako zamiešaný dataset\n",
        "\n",
        "    # Rozdelenie datasetu\n",
        "    df_dev = df[:development]\n",
        "    df_test = df[development:development + test]\n",
        "    df_train = df[development + test:]\n",
        "\n",
        "    def vytvorenie_suboru(df, source_subor, target_subor):\n",
        "        df['Source'].to_csv(source_subor, index=False, header=False, quoting=csv.QUOTE_NONE, sep=',')\n",
        "        df['Target'].to_csv(target_subor, index=False, header=False, quoting=csv.QUOTE_NONE, sep=',')\n",
        "\n",
        "\n",
        "    vytvorenie_suboru(df_train, source_subor + '.train', target_subor + '.train')\n",
        "    vytvorenie_suboru(df_dev, source_subor + '.dev', target_subor + '.dev')\n",
        "    vytvorenie_suboru(df_test, source_subor + '.test', target_subor + '.test')\n",
        "\n",
        "\n",
        "train_test_dev(development, test, source_subor, target_subor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bKTRESdMD1NB"
      },
      "outputs": [],
      "source": [
        "source_test = r\"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/source_subworded.test\"\n",
        "target_test = r\"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/target_subworded.test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex43E6oqDmiM",
        "outputId": "e5fcc190-c6cf-478a-df48-6529fb03564e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁firstly ▁there ▁are ▁insufficient ▁organs ▁available ▁in ▁the ▁eu\n",
            "▁there ▁is ▁poverty ▁in ▁the ▁world\n",
            "▁the ▁european ▁union ▁does ▁indeed ▁require ▁ambition ▁to ▁defeat ▁the ▁challenges ▁presented ▁by ▁the ▁crisis ▁but ▁that ▁ambition ▁must ▁not ▁cause ▁problems ▁for ▁the ▁effort ▁at ▁budget ary ▁consolidation ▁which ▁is ▁being ▁demanded ▁of ▁member ▁states ▁in ▁view ▁of ▁the ▁weakness ▁of ▁their ▁public ▁accounts ▁and ▁their ▁excessive ▁deficits\n",
            "▁however ▁the ▁different ▁implementation ▁methods ▁of ▁member ▁states ▁have ▁made ▁it ▁difficult ▁for ▁the ▁service ▁sector ▁to ▁take ▁full ▁advantage ▁of ▁the ▁directive\n",
            "▁i ▁voted ▁for ▁the ▁report ▁on ▁the ▁demographic ▁challenge ▁and ▁solidarity ▁between ▁generations ▁because ▁under ▁the ▁current ▁circumstances ▁of ▁the ▁unprecedented ▁demographic ▁problems ▁posed ▁by ▁increased ▁life ▁expectancy ▁and ▁falling ▁birth ▁rates ▁they ▁constitute ▁one ▁of ▁the ▁most ▁urgent ▁social ▁policy ▁challenges ▁of ▁coming ▁years\n",
            "▁with ▁a ▁fixed ▁national ▁exchange ▁rate ▁the ▁civil ▁liability ▁of ▁borrow ers ▁towards ▁lend ers ▁was ▁ very ▁high ▁all ▁the ▁currency ▁risk ▁in ▁the ▁value ▁of ▁an ▁over pr ic ed ▁pledge ▁was ▁borne ▁by ▁borrow ers\n",
            "\n",
            "▁po ▁prvé ▁v ▁eú ▁je ▁nedostatok ▁orgánov\n",
            "▁vo ▁svete ▁je ▁chudoba\n",
            "▁európska ▁únia ▁skutočne ▁vyžaduje ▁a m b íci u ▁riešiť ▁problémy ▁spôsobené ▁krízou ▁ale ▁táto ▁a m b íci a ▁nesmie ▁ skom pl ik ovať ▁úsilie ▁v ▁oblasti ▁rozpočtov ej ▁konsolidáci e ▁ktorá ▁sa ▁od ▁členských ▁štátov ▁vyžaduje ▁v ▁dôsledku ▁osla b enia ▁verejných ▁financií ▁a ▁ich ▁nadmern ého ▁deficit u\n",
            "▁rozdielne ▁metódy ▁vykonávania ▁v ▁členských ▁štátoch ▁však ▁odvetviu ▁služieb ▁sťaž ili ▁optimáln e ▁z u ži tk ovanie ▁výhod ▁smernice\n",
            "▁hlasoval ▁som ▁za ▁správu ▁o ▁demografick ých ▁výzva ch ▁a ▁solidarite ▁medzi ▁generácia mi ▁pretože ▁v ▁súčasnej ▁situácii ▁ne b ý val ých ▁demografick ých ▁problémov ▁ktoré ▁sú ▁spôsobené ▁pred l ž ovaním ▁očakáva nej ▁d ĺ ž ky ▁života ▁a ▁pokles om ▁miery ▁pôrod nosti ▁predstavujú ▁jednu ▁z ▁naj nal ie ha v ejších ▁výziev ▁sociálnej ▁politiky ▁nasledujúcich ▁rokov\n",
            "▁vďaka ▁pevn ému ▁národné mu ▁v ý men né mu ▁kurz u ▁bola ▁občiansk o práv na ▁zodpovednosť ▁ dl ž níkov ▁v oči ▁veriteľ om ▁veľmi ▁vysoká ▁celé ▁menové ▁riziko ▁v ▁hodnote ▁pred ra že nej ▁záruky ▁z ná š ali ▁ dl ž níci\n"
          ]
        }
      ],
      "source": [
        "with open(source_test, \"r\", encoding=\"utf-8\") as file:\n",
        "    for i, line in enumerate(file):\n",
        "        print(line.strip())\n",
        "        if i >= 5:\n",
        "            break\n",
        "\n",
        "print()\n",
        "\n",
        "with open(target_test, \"r\", encoding=\"utf-8\") as file:\n",
        "    for i, line in enumerate(file):\n",
        "        print(line.strip())\n",
        "        if i >= 5:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Hnqodi2iQ2CX"
      },
      "outputs": [],
      "source": [
        "config = '''\n",
        "\n",
        "seed: 42 # aby sme dosiahli rovnakých výsledkov a pre lepšie porovnávanie medzi modelmi\n",
        "\n",
        "save_data: vocab  # zložka, kde sa uloží slovná zásoba vygenerovaná pomocou onmt_build_vocab\n",
        "\n",
        "data:\n",
        "    corpus:\n",
        "        # súbory určené na trénovanie\n",
        "        path_src: /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/source_subworded.train\n",
        "        path_tgt: /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/target_subworded.train\n",
        "        transforms: [filtertoolong]\n",
        "        weight: 1\n",
        "    valid:\n",
        "        # súbory určené na validáciu\n",
        "        path_src: /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/source_subworded.dev\n",
        "        path_tgt: /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/target_subworded.dev\n",
        "        transforms: [filtertoolong]\n",
        "\n",
        "# súbory, v ktorých je uložená slovná zásoba pre source (anglický jazyk) a target (slovenský jazyk) onmt_build_vocab\n",
        "src_vocab: vocab/source.vocab\n",
        "tgt_vocab: vocab/target.vocab\n",
        "\n",
        "# veľkosť slovnej zásoby - hodnoty by mali byť rovnaké ako v sentencepiece\n",
        "src_vocab_size: 8000\n",
        "tgt_vocab_size: 8000\n",
        "\n",
        "src_subword_model: /content/source.model\n",
        "tgt_subword_model: /content/target.model\n",
        "\n",
        "# Miesto uloženia súborov\n",
        "log_file:   /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/train.log\n",
        "save_model: /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/complete_model\n",
        "\n",
        "train_steps: 100000 # počet krokov trénovania\n",
        "valid_steps: 10000  # po n krokoch vykonať validáciu pomocou dev setu\n",
        "warmup_steps: 8000 # počet by mal byť priamoúmerný počtu krokov trénovania\n",
        "early_stopping: 4 # ak sa model nezlepší po n validáciach, trénovanie zastaví\n",
        "save_checkpoint_steps: 5000   # uloženie modelu po n krokoch\n",
        "keep_checkpoint: 10  # počet posledných n uložených modelov\n",
        "report_every: 500 # výpis informácií o trénovaní po n-krokoch\n",
        "\n",
        "decoder_type: transformer\n",
        "encoder_type: transformer\n",
        "word_vec_size: 512   # dimenzionálnosť word embeddingu\n",
        "hidden_size: 512     # dimenzionálnosť skrytých stavov v enkódery a dekódery\n",
        "layers: 6             # počet vrstiev v enkódery a dekódery   - alternatíva je enc_layers a dec_layers\n",
        "transformer_ff: 2048  # dimenzionálnosť doprednej vrstvy v transformery\n",
        "heads: 8              # počet attention head v multi-head-attention\n",
        "\n",
        "accum_count: 2 # počet n krokov, po ktorých sa aktualizujú parametre\n",
        "optim: adam\n",
        "adam_beta1: 0.9\n",
        "adam_beta2: 0.998\n",
        "decay_method: noam\n",
        "learning_rate: 2.0    # miera učenia\n",
        "max_grad_norm: 0.0    # gradient clipping, pomáha, aby v modely nenastal explodujúci gradient (nemožnosť modelu sa učiť v dôsledku vysokej miery učenia), emôže pomôcť pre lepšiu stabilitu modelu\n",
        "\n",
        "param_init: 0.0\n",
        "param_init_glorot: 'true'\n",
        "position_encoding: 'true'\n",
        "\n",
        "batch_size: 1024\n",
        "valid_batch_size: 1024\n",
        "batch_type: tokens\n",
        "normalization: tokens\n",
        "max_generator_batches: 2\n",
        "\n",
        "dropout: 0.1           # regularizácia, ktorá vytvára šancu (0.1 = 10%) na \"vypnutie\" nodu vo vrstve behom trénovania, pomáha proti overfittingu\n",
        "label_smoothing: 0.1\n",
        "\n",
        "world_size: 1\n",
        "gpu_ranks: 0\n",
        "\n",
        "# INFO\n",
        "log_file: train.log\n",
        "log_level: INFO\n",
        "\n",
        "'''\n",
        "\n",
        "with open(\"config.yaml\", \"w+\", encoding=\"utf-8\") as config_yaml:\n",
        "  config_yaml.write(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sQvEi-oUaTp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1fb94d1-c7a0-4993-8d51-a7337cbbf2f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-2ad78e68-7908-2501-57d8-2e092505cd05)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UATW2mh1SYHe"
      },
      "source": [
        "Použíjeme Framework OpenNMT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noLMeIygRw8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed0f1154-574b-4c17-c179-4460498f5784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2024-02-24 13:56:54,917 INFO] Counter vocab from -1 samples.\n",
            "[2024-02-24 13:56:54,917 INFO] n_sample=-1: Build vocab on full datasets.\n",
            "[2024-02-24 13:57:25,943 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=26)\n",
            "\n",
            "[2024-02-24 13:57:25,965 INFO] Counters src: 8070\n",
            "[2024-02-24 13:57:25,965 INFO] Counters tgt: 8052\n"
          ]
        }
      ],
      "source": [
        "# Vytvorenie vocabulary\n",
        "!onmt_build_vocab -config config.yaml -n_sample -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCIZCKtkUH83"
      },
      "outputs": [],
      "source": [
        "# Trénovanie the NMT model\n",
        "!onmt_train -config config.yaml -gpu_ranks 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R8EYgvfvDMy"
      },
      "source": [
        "## Preklad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4FKodPwvIWx"
      },
      "outputs": [],
      "source": [
        "config_translate = '''\n",
        "\n",
        "model: /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/complete_model_step_35000.pt     # sem vložiť najlepší model trénovania\n",
        "src: /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/source_subworded.test\n",
        "output: /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/translated\n",
        "\n",
        "log_file: translate.log\n",
        "\n",
        "seed: 42\n",
        "\n",
        "beam_size: 4\n",
        "min_length: 1\n",
        "length_penalty: avg\n",
        "\n",
        "batch_size: 32\n",
        "gpu: 0\n",
        "\n",
        "coverage_penalty: summary\n",
        "beta: 0.5\n",
        "\n",
        "'''\n",
        "\n",
        "with open(\"config_translated.yaml\", \"w+\", encoding=\"utf-8\") as config_yaml:\n",
        "  config_yaml.write(config_translate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQ0AMr65aU2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d4ac81-c501-4de1-f7f2-42f9b278494a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-02-25 10:54:14,376 INFO] Loading checkpoint from /content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/complete_model_step_35000.pt\n",
            "[2024-02-25 10:54:27,975 INFO] Loading data into the model\n",
            "[2024-02-25 10:55:22,192 INFO] PRED SCORE: -4.8122, PRED PPL: 123.01 NB SENTENCES: 4000\n",
            "Time w/o python interpreter load/terminate:  68.28334426879883\n"
          ]
        }
      ],
      "source": [
        "# Preklad\n",
        "!onmt_translate -config config_translated.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgmIvlbOaXv7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08be24f4-e88e-4359-d950-9139843bf7e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁v ▁súčasnej ▁situácii ▁by ▁mala ▁európska ▁únia ▁venovať ▁osobitnú ▁pozornosť ▁svojim ▁ 2 0 ▁milió nom ▁malých ▁a ▁stredných ▁podnikov\n",
            "▁takéto ▁opatrenie ▁nám ▁umožní ▁zab iť ▁niekoľko ▁v tá kov ▁jednou ▁r anou ▁je ▁to ▁účinný ▁nástroj ▁proti ▁špeku l áciám ▁a ▁príjmy ▁nám ▁umožnia ▁riešiť ▁vlád ne ▁defici ty ▁a ▁financovanie ▁naliehav ých ▁sociálnych ▁projektov ▁životného ▁prostredia ▁rozvojovej ▁pomoci ▁projektov ▁infraštruktúry ▁atď\n",
            "▁tento ▁návrh ▁referen čného ▁rámca ▁nie ▁je ▁hroz bou ▁pre ▁spôsob ▁akým ▁členské ▁štáty ▁organiz ujú ▁odborné ▁vzdelávanie ▁v ▁európe ▁ale ▁môžeme ▁stav ať ▁na ▁tradí cii ▁ktorú ▁máme ▁bez ▁ohľadu ▁na ▁to ▁či ▁je ▁organiz ovaná ▁na ▁miestnej ▁regionálnej ▁alebo ▁národnej ▁úrovni\n",
            "▁v ▁týchto ▁veciach ▁sa ▁toho ▁veľa ▁hod ilo ▁takže ▁zač ni me ▁pripomenu tím ▁kľúčových ▁fak tov\n",
            "▁toto ▁očakávajú ▁občania ▁spotrebitelia ▁od ▁parlamentu ▁aj ▁rady\n",
            "▁v ▁tejto ▁súvislosti ▁podporujem ▁pozmeňujúci ▁a ▁doplňujúci ▁návrh ▁ 2 ▁predložený ▁skupinou ▁zelených ▁ktorý ▁žiada ▁podstatné ▁posilnenie ▁európskeho ▁regula čného ▁a ▁dozor ného ▁rámca ▁s ▁cieľom ▁udržať ▁finančnú ▁stabilitu\n",
            "\n"
          ]
        }
      ],
      "source": [
        "translated = r\"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/translated\"\n",
        "with open(translated, \"r\", encoding=\"utf-8\") as file:\n",
        "    for i, line in enumerate(file):\n",
        "        print(line.strip())\n",
        "        if i >= 5:\n",
        "            break\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6flpTjHkaY-g"
      },
      "outputs": [],
      "source": [
        "target_model = r\"/content/target.model\"\n",
        "translation = r\"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/translated\"\n",
        "translation_desubword = translation + \".desubword\"\n",
        "\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(target_model)\n",
        "\n",
        "# Desubword prekladový súbor\n",
        "with open(translation, encoding='utf-8') as vstup, open(translation, \"w\", encoding='utf-8') as vystup:\n",
        "    for line in vstup:\n",
        "        desub = sp.decode_pieces(line.strip().split(\" \"))\n",
        "        vystup.write(desub + \"\\n\")\n",
        "\n",
        "print(f\"Dekódovanie bolo dokončené! Výstupný súbor: {translation_desubword}\")\n",
        "\n",
        "target_test = r\"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/target_subworded.test\"\n",
        "target_test_desubword = target_test + \".desubword\"\n",
        "\n",
        "with open(target_test, encoding='utf-8') as vstup, open(target_test_desubword, \"w\", encoding='utf-8') as vystup:\n",
        "    for line in vstup:\n",
        "        desub = sp.decode_pieces(line.strip().split(\" \"))\n",
        "        vystup.write(desub + \"\\n\")\n",
        "\n",
        "print(f\"Dekódovanie bolo dokončené! Výstupný súbor: {target_test_desubword}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibTSQf5HbPfw"
      },
      "outputs": [],
      "source": [
        "reference = r\"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/target_subworded.test.desubword\"\n",
        "preklad = r\"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/translated.desubword\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(reference, \"r\", encoding=\"utf-8\") as file:\n",
        "    for i, line in enumerate(file):\n",
        "        print(line.strip())\n",
        "        if i >= 5:\n",
        "            break\n",
        "\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EVAw1ioMaur",
        "outputId": "b657660d-4e0d-453c-9646-64a7faccf6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v súčasnej situácii by mala európska únia osobitnú pozornosť venovať svojim 20 miliónom malých a stredných podnikov\n",
            "takéto opatrenie nám umožní zabiť niekoľko múch jednou ranou je účinným nástrojom proti špekuláciám a príjmy nám umožnia poradiť si so štátnymi deficitmi a financovaním naliehavých sociálnych projektov životné prostredie rozvojová pomoc infraštruktúrne projekty atď\n",
            "tento návrh na referenčný rámec neohrozuje spôsob organizovania odborného vzdelávania v členských štátoch v celej európe môžeme však budovať na tradícii ktorú máme bez ohľadu na to či je organizované na miestnej regionálnej alebo vnútroštátnej úrovni\n",
            "na písanie o týchto problémoch sa už vyplytvalo veľa atramentu začneme teda pripomenutím základných faktov\n",
            "to od parlamentu a rady očakávajú občania spotrebitelia\n",
            "v súvislosti s tým podporujem pozmeňujúci a doplňujúci návrh č 2 ktorý predložila skupina zelených a ktorý si vyžaduje podstatné posilnenie regulačného a dozorného rámca eú s cieľom zachovať finančnú stabilitu\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3MFttHDbWmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96291731-ed6a-4ef4-ef9e-30cfcb690228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v súčasnej situácii by mala európska únia venovať osobitnú pozornosť svojim 20 miliónom malých a stredných podnikov\n",
            "takéto opatrenie nám umožní zabiť niekoľko vtákov jednou ranou je to účinný nástroj proti špekuláciám a príjmy nám umožnia riešiť vládne deficity a financovanie naliehavých sociálnych projektov životného prostredia rozvojovej pomoci projektov infraštruktúry atď\n",
            "tento návrh referenčného rámca nie je hrozbou pre spôsob akým členské štáty organizujú odborné vzdelávanie v európe ale môžeme stavať na tradícii ktorú máme bez ohľadu na to či je organizovaná na miestnej regionálnej alebo národnej úrovni\n",
            "v týchto veciach sa toho veľa hodilo takže začnime pripomenutím kľúčových faktov\n",
            "toto očakávajú občania spotrebitelia od parlamentu aj rady\n",
            "v tejto súvislosti podporujem pozmeňujúci a doplňujúci návrh 2 predložený skupinou zelených ktorý žiada podstatné posilnenie európskeho regulačného a dozorného rámca s cieľom udržať finančnú stabilitu\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open(preklad, \"r\", encoding=\"utf-8\") as file:\n",
        "    for i, line in enumerate(file):\n",
        "        print(line.strip())\n",
        "        if i >= 5:\n",
        "            break\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install spacy"
      ],
      "metadata": {
        "id": "WODrM4Wo3H6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download xx_ent_wiki_sm"
      ],
      "metadata": {
        "id": "4cXohf183C1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d1448b-3aa8-44e3-a50e-eac186c3de8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xx-ent-wiki-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/xx_ent_wiki_sm-3.7.0/xx_ent_wiki_sm-3.7.0-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from xx-ent-wiki-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.1.5)\n",
            "Installing collected packages: xx-ent-wiki-sm\n",
            "Successfully installed xx-ent-wiki-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('xx_ent_wiki_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import sacrebleu\n",
        "from nltk.translate import meteor_score as ms\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "nlp = spacy.load(\"xx_ent_wiki_sm\") #https://github.com/explosion/spacy-models/releases/tag/xx_ent_wiki_sm-3.7.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TXq81Lq2sjn",
        "outputId": "3be529ef-e70e-444c-e466-df0706328a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference = r\"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/target_subworded.test.desubword\"\n",
        "preklad = r\"/content/drive/MyDrive/Colab_Notebooks/Diplomovka/Dáta/europarl/translated.desubword\""
      ],
      "metadata": {
        "id": "diNDH7rPzl_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_Mm6k99ba9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f70764-4cc1-4ba7-bdd7-dfe5c22997b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Referenčná veta v SK jazyku: v súčasnej situácii by mala európska únia osobitnú pozornosť venovať svojim 20 miliónom malých a stredných podnikov\n",
            "Preložená veta:\t\t     v súčasnej situácii by mala európska únia venovať osobitnú pozornosť svojim 20 miliónom malých a stredných podnikov\n",
            "BLEU:   35.86040111007451\n",
            "METEOR:  0.9934866680236109\n"
          ]
        }
      ],
      "source": [
        "# referenčné hodnoty\n",
        "refs = []\n",
        "\n",
        "with open(reference, encoding='utf-8') as reference:\n",
        "    for line in reference:\n",
        "        line = line.strip()\n",
        "        refs.append(line)\n",
        "\n",
        "print(\"Referenčná veta v SK jazyku:\", refs[0]) # výpis prvej referenčenj vety, pomocou ktorej budeme porovnávať vety\n",
        "\n",
        "refs = [refs]  # list listov, teda forma, ktorú si vyžaduje SacreBLEU\n",
        "\n",
        "# hodnoty, ktoré sme preložili\n",
        "preds = []\n",
        "\n",
        "with open(preklad, encoding='utf-8') as prek:\n",
        "    for line in prek:\n",
        "        line = line.strip()\n",
        "        preds.append(line)\n",
        "\n",
        "print(\"Preložená veta:\\t\\t    \", preds[0]) # výpis prvého preloženého riadka\n",
        "\n",
        "# BLEU skóre - výpočet BLEU na základe porovnania referenčných viet s preloženými vetami\n",
        "bleu = sacrebleu.corpus_bleu(preds, refs)\n",
        "print(\"BLEU:  \", bleu.score)\n",
        "\n",
        "# tokenizácia je potrebná pre rozdelenie viet do menších častí (tokenov), aby Meteor dokázal porovnávať slová a ich význam\n",
        "def tokenizacia(text):\n",
        "    doc = nlp(text)\n",
        "    return [token.text for token in doc]\n",
        "\n",
        "meteor_scores = []\n",
        "for refs_segment, pred in zip(refs, preds):\n",
        "    ref = refs_segment[0]\n",
        "    token_ref = tokenizacia(ref) # tokenizácia referenčných viet\n",
        "    token_pred = tokenizacia(pred) # tokenizáci preložených viet\n",
        "\n",
        "    # Výpočet METEOR skóre - meteor skóre narozdiel od bleu zohľadnuje sémantiku do istej miery\n",
        "    score = ms.meteor_score([token_ref], token_pred) # výpočet meteor skóre pre jednu vetu\n",
        "    meteor_scores.append(score)\n",
        "\n",
        "average_meteor_score = sum(meteor_scores) / len(meteor_scores) # výpočet priemeru Meteor skóre, pre celú množinu preložených viet\n",
        "print(\"METEOR: \", average_meteor_score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_ref"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zqE2czPyCSH",
        "outputId": "37f5a63d-7a61-4def-ee16-0afe07b0f615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['v',\n",
              " 'súčasnej',\n",
              " 'situácii',\n",
              " 'by',\n",
              " 'mala',\n",
              " 'európska',\n",
              " 'únia',\n",
              " 'osobitnú',\n",
              " 'pozornosť',\n",
              " 'venovať',\n",
              " 'svojim',\n",
              " '20',\n",
              " 'miliónom',\n",
              " 'malých',\n",
              " 'a',\n",
              " 'stredných',\n",
              " 'podnikov']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTJvW8pz1q4I",
        "outputId": "a1f0d92b-d5ff-497a-8904-f4e50f88bd6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['v',\n",
              " 'súčasnej',\n",
              " 'situácii',\n",
              " 'by',\n",
              " 'mala',\n",
              " 'európska',\n",
              " 'únia',\n",
              " 'venovať',\n",
              " 'osobitnú',\n",
              " 'pozornosť',\n",
              " 'svojim',\n",
              " '20',\n",
              " 'miliónom',\n",
              " 'malých',\n",
              " 'a',\n",
              " 'stredných',\n",
              " 'podnikov']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "s91Kg0emqsx8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1cAbr53bSx53865fbKZe58vxyASVtO7ub",
      "authorship_tag": "ABX9TyMJO164LkZYynWoml5ocucr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}